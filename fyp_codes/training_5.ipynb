{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4c870f-52f3-49c8-9751-bd9fca98a097",
   "metadata": {},
   "source": [
    "### training_5 using nn.Dropout() to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176b093-0554-428a-9d32-5910d21a48fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### UNet architecture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fb046c-94f7-43d6-88af-baec311fdc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        # Regularization to reduce overfitting\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "       \n",
    "        # ENCODER\n",
    "        # customize each layer of double conv\n",
    "        self.down_conv_1 = self.doubleConv(1,64)\n",
    "        self.down_conv_2 = self.doubleConv(64,128)\n",
    "        self.down_conv_3 = self.doubleConv(128,256)\n",
    "        self.down_conv_4 = self.doubleConv(256,512)\n",
    "        self.down_conv_5 = self.doubleConv(512,1024)\n",
    "        \n",
    "        # DECODER\n",
    "        self.up_conv_1 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=(2,2), stride=(2,2))\n",
    "        self.up_conv_2 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(2,2), stride=(2,2))\n",
    "        self.up_conv_3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(2,2), stride=(2,2))\n",
    "        self.up_conv_4 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(2,2), stride=(2,2))\n",
    "        \n",
    "        self.down_conv_6 = self.doubleConv(1024,512)\n",
    "        self.down_conv_7 = self.doubleConv(512,256)\n",
    "        self.down_conv_8 = self.doubleConv(256,128)\n",
    "        self.down_conv_9 = self.doubleConv(128,64)\n",
    "\n",
    "        self.down_conv_final = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=(1,1))\n",
    "        \n",
    "    def doubleConv(self, in_c, out_c):\n",
    "        conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_c, out_channels=out_c, kernel_size=(3,3)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=out_c, out_channels=out_c, kernel_size=(3,3)),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        return conv\n",
    "    \n",
    "    def cropping(self, ori_tensor, target_tensor):\n",
    "        # assuming image is perfect square\n",
    "        ori_tensor_width = ori_tensor.shape[3]\n",
    "        target_tensor_width = target_tensor.shape[3]\n",
    "        delta = ori_tensor_width - target_tensor_width\n",
    "        delta = delta // 2 # assume perfect square\n",
    "        return ori_tensor[:,:,delta:ori_tensor_width-delta, delta:ori_tensor_width-delta]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        x1 = self.down_conv_1(x)# output got concatenated\n",
    "        x2 = self.maxpool(x1)\n",
    "        x3 = self.down_conv_2(x2)# output got concatenated\n",
    "        x4 = self.maxpool(x3)\n",
    "        x5 = self.down_conv_3(x4)# output got concatenated\n",
    "        x6 = self.maxpool(x5)\n",
    "        x7 = self.down_conv_4(x6)# output got concatenated\n",
    "        x8 = self.maxpool(x7)\n",
    "        x9 = self.down_conv_5(x8)\n",
    "        \n",
    "        # decoder\n",
    "        x10 = self.up_conv_1(x9)\n",
    "        x10 = self.dropout(x10)\n",
    "        x11 = torch.cat((x10,self.cropping(x7,x10)), dim=1)\n",
    "\n",
    "        x12 = self.down_conv_6(x11)\n",
    "\n",
    "        x13 = self.up_conv_2(x12)\n",
    "        x13 = self.dropout(x13)\n",
    "        x14 = torch.cat((x13,self.cropping(x5,x13)), dim=1)\n",
    "\n",
    "        x15 = self.down_conv_7(x14)\n",
    "\n",
    "        x16 = self.up_conv_3(x15)\n",
    "        x16 = self.dropout(x16)\n",
    "        x17 = torch.cat((x16,self.cropping(x3,x16)), dim=1)\n",
    "\n",
    "        x18 = self.down_conv_8(x17)\n",
    "\n",
    "        x19 = self.up_conv_4(x18)\n",
    "        x19 = self.dropout(x19)\n",
    "        x20 = torch.cat((x19,self.cropping(x1,x19)), dim=1)\n",
    "\n",
    "        x21 = self.down_conv_9(x20)\n",
    "\n",
    "        x22 = self.down_conv_final(x21)\n",
    "        return x22\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffc0197-f511-46b2-b63c-24cbaaf0facb",
   "metadata": {},
   "source": [
    "#### MultiInputNet architecture class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf70f5ca-93ff-45b6-8ded-969b747f2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiInputNet(nn.Module):\n",
    "    def __init__(self, landmark_input_size=64, landmark_output_size=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        # image pathway (Dense UNet)\n",
    "        self.u_net = UNet()\n",
    "        self.u_net = self.u_net.to(device)\n",
    "        \n",
    "        # landmark pathway\n",
    "        self.landmark_input_size = landmark_input_size\n",
    "        self.landmark_output_size = landmark_output_size\n",
    "        self.landmark_fc = nn.Linear(self.landmark_input_size, self.landmark_output_size)\n",
    "        \n",
    "        # combined pathway\n",
    "        self.combined_fc = None\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 3)\n",
    "        \n",
    "        # dropout feed forward for regularization\n",
    "        self.dropout = nn.Dropout(0.2)  # Dropout layer with dropout rate of 0.5\n",
    "\n",
    "        # activation fn\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, image, landmark):\n",
    "        # unet process\n",
    "        image_features = self.u_net(image)\n",
    "        # landmark process\n",
    "        landmark_features = self.landmark_fc(landmark)\n",
    "        \n",
    "        # combined features\n",
    "        # img_b4_flat = image_features\n",
    "        # land_b4_flat = landmark_features\n",
    "        # print(\"Image before flatten \", img_b4_flat.shape)\n",
    "        # print(\"landmark before flatten \", land_b4_flat.shape)\n",
    "        \n",
    "        # flatten both tensor before concatenating, exclude batch_size in BCHW, only flatten CHW\n",
    "        flatten_img = torch.flatten(image_features, start_dim=1) \n",
    "        flatten_land = torch.flatten(landmark_features, start_dim=1)\n",
    "        \n",
    "        # print(\"Image after flatten \", flatten_img.shape)\n",
    "        # print(\"landmark after flatten \", flatten_land.shape)\n",
    "\n",
    "        combined_features = torch.cat((flatten_img,flatten_land), dim=1)\n",
    "        # print(\"Combined_features \", combined_features.shape)\n",
    "        combined_features = combined_features.to(device)\n",
    "        \n",
    "        # now set the self.combined_fc.in_features dynamically\n",
    "        if self.combined_fc is None:\n",
    "            self.combined_fc = nn.Linear(in_features=combined_features.shape[1], out_features=64) #combined_features.shape = 301152\n",
    "            self.combined_fc = self.combined_fc.to(device)\n",
    "        \n",
    "        x = self.combined_fc(combined_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153c023-b87e-49f0-9742-e9e05ce93dfd",
   "metadata": {},
   "source": [
    "#### Define cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a07f7ae-d4df-4ce5-a403-3b193d5c0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f92f0-7cb1-4256-bb94-9d6595464459",
   "metadata": {},
   "source": [
    "#### Import training and test dataset from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65136f6a-769f-4b74-858d-1b2f5facc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23117b88-77c9-439b-99dd-ddee55e8c15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT</th>\n",
       "      <th>MT</th>\n",
       "      <th>TL/L</th>\n",
       "      <th>image_training_file</th>\n",
       "      <th>cobb_angle_training_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.2069</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.261400</td>\n",
       "      <td>sunhl-1th-02-Jan-2017-162 A AP.jpg</td>\n",
       "      <td>sunhl-1th-02-Jan-2017-162 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.8107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.851886</td>\n",
       "      <td>sunhl-1th-02-Jan-2017-162 B AP.jpg</td>\n",
       "      <td>sunhl-1th-02-Jan-2017-162 B AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.1172</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sunhl-1th-03-Jan-2017-163 A AP.jpg</td>\n",
       "      <td>sunhl-1th-03-Jan-2017-163 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.8144</td>\n",
       "      <td>8.60388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sunhl-1th-03-Jan-2017-163 B AP.jpg</td>\n",
       "      <td>sunhl-1th-03-Jan-2017-163 B AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.1538</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.748480</td>\n",
       "      <td>sunhl-1th-03-Jan-2017-164 A AP.jpg</td>\n",
       "      <td>sunhl-1th-03-Jan-2017-164 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>12.5325</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>11.484000</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-159 A AP2.jpg</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-159 A AP2.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>11.0118</td>\n",
       "      <td>10.37890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-159 B AP.jpg</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-159 B AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>5.6424</td>\n",
       "      <td>3.95370</td>\n",
       "      <td>2.821400</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-159 C AP.jpg</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-159 C AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>16.3437</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-160 A AP.jpg</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-160 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>13.6437</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.947430</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-161 A AP.jpg</td>\n",
       "      <td>sunhl-1th-30-Dec-2016-161 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PT        MT       TL/L                  image_training_file  \\\n",
       "0     6.2069   0.00000   1.261400   sunhl-1th-02-Jan-2017-162 A AP.jpg   \n",
       "1    23.8107   0.00000   0.851886   sunhl-1th-02-Jan-2017-162 B AP.jpg   \n",
       "2    21.1172   0.00000   0.000000   sunhl-1th-03-Jan-2017-163 A AP.jpg   \n",
       "3    10.8144   8.60388   0.000000   sunhl-1th-03-Jan-2017-163 B AP.jpg   \n",
       "4    18.1538   0.00000   1.748480   sunhl-1th-03-Jan-2017-164 A AP.jpg   \n",
       "..       ...       ...        ...                                  ...   \n",
       "476  12.5325   0.00000  11.484000  sunhl-1th-30-Dec-2016-159 A AP2.jpg   \n",
       "477  11.0118  10.37890   0.000000   sunhl-1th-30-Dec-2016-159 B AP.jpg   \n",
       "478   5.6424   3.95370   2.821400   sunhl-1th-30-Dec-2016-159 C AP.jpg   \n",
       "479  16.3437   0.00000   0.000000   sunhl-1th-30-Dec-2016-160 A AP.jpg   \n",
       "480  13.6437   0.00000   6.947430   sunhl-1th-30-Dec-2016-161 A AP.jpg   \n",
       "\n",
       "                    cobb_angle_training_file  \n",
       "0     sunhl-1th-02-Jan-2017-162 A AP.jpg.mat  \n",
       "1     sunhl-1th-02-Jan-2017-162 B AP.jpg.mat  \n",
       "2     sunhl-1th-03-Jan-2017-163 A AP.jpg.mat  \n",
       "3     sunhl-1th-03-Jan-2017-163 B AP.jpg.mat  \n",
       "4     sunhl-1th-03-Jan-2017-164 A AP.jpg.mat  \n",
       "..                                       ...  \n",
       "476  sunhl-1th-30-Dec-2016-159 A AP2.jpg.mat  \n",
       "477   sunhl-1th-30-Dec-2016-159 B AP.jpg.mat  \n",
       "478   sunhl-1th-30-Dec-2016-159 C AP.jpg.mat  \n",
       "479   sunhl-1th-30-Dec-2016-160 A AP.jpg.mat  \n",
       "480   sunhl-1th-30-Dec-2016-161 A AP.jpg.mat  \n",
       "\n",
       "[481 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "dataset_training_csv_path = 'C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\training_dataset\\\\angles_ap_labelled_training.csv'\n",
    "dataset_training_csv = pd.read_csv(dataset_training_csv_path)\n",
    "dataset_training_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02858d20-4345-4aee-8cf5-d8275d0c0355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT</th>\n",
       "      <th>MT</th>\n",
       "      <th>TL/L</th>\n",
       "      <th>image_test_file</th>\n",
       "      <th>cobb_angle_test_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.5578</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.938543</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-310 C AP.jpg</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-310 C AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4942</td>\n",
       "      <td>1.00940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-310 a ap.jpg</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-310 a ap.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0048</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.501069</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-311 A AP.jpg</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-311 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.3802</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.422200</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-311 C AP.jpg</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-311 C AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1798</td>\n",
       "      <td>1.23238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-311 D AP.jpg</td>\n",
       "      <td>sunhl-1th-01-Mar-2017-311 D AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>7.8933</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.726000</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-307 B AP.jpg</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-307 B AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>22.5108</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.726900</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-308 A AP.jpg</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-308 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>9.3330</td>\n",
       "      <td>0.73155</td>\n",
       "      <td>6.376700</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-309 A AP.jpg</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-309 A AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>17.5526</td>\n",
       "      <td>8.90332</td>\n",
       "      <td>1.856840</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-309 B AP.jpg</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-309 B AP.jpg.mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>14.7518</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.070970</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-310 B AP.jpg</td>\n",
       "      <td>sunhl-1th-28-Feb-2017-310 B AP.jpg.mat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PT       MT       TL/L                     image_test_file  \\\n",
       "0    12.5578  0.00000   0.938543  sunhl-1th-01-Mar-2017-310 C AP.jpg   \n",
       "1     7.4942  1.00940   0.000000  sunhl-1th-01-Mar-2017-310 a ap.jpg   \n",
       "2    14.0048  0.00000   0.501069  sunhl-1th-01-Mar-2017-311 A AP.jpg   \n",
       "3    13.3802  0.00000   1.422200  sunhl-1th-01-Mar-2017-311 C AP.jpg   \n",
       "4    16.1798  1.23238   0.000000  sunhl-1th-01-Mar-2017-311 D AP.jpg   \n",
       "..       ...      ...        ...                                 ...   \n",
       "123   7.8933  0.00000   1.726000  sunhl-1th-28-Feb-2017-307 B AP.jpg   \n",
       "124  22.5108  0.00000  14.726900  sunhl-1th-28-Feb-2017-308 A AP.jpg   \n",
       "125   9.3330  0.73155   6.376700  sunhl-1th-28-Feb-2017-309 A AP.jpg   \n",
       "126  17.5526  8.90332   1.856840  sunhl-1th-28-Feb-2017-309 B AP.jpg   \n",
       "127  14.7518  0.00000   5.070970  sunhl-1th-28-Feb-2017-310 B AP.jpg   \n",
       "\n",
       "                       cobb_angle_test_file  \n",
       "0    sunhl-1th-01-Mar-2017-310 C AP.jpg.mat  \n",
       "1    sunhl-1th-01-Mar-2017-310 a ap.jpg.mat  \n",
       "2    sunhl-1th-01-Mar-2017-311 A AP.jpg.mat  \n",
       "3    sunhl-1th-01-Mar-2017-311 C AP.jpg.mat  \n",
       "4    sunhl-1th-01-Mar-2017-311 D AP.jpg.mat  \n",
       "..                                      ...  \n",
       "123  sunhl-1th-28-Feb-2017-307 B AP.jpg.mat  \n",
       "124  sunhl-1th-28-Feb-2017-308 A AP.jpg.mat  \n",
       "125  sunhl-1th-28-Feb-2017-309 A AP.jpg.mat  \n",
       "126  sunhl-1th-28-Feb-2017-309 B AP.jpg.mat  \n",
       "127  sunhl-1th-28-Feb-2017-310 B AP.jpg.mat  \n",
       "\n",
       "[128 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "dataset_test_csv_path = 'C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\test_dataset\\\\angles_ap_labelled_test.csv'\n",
    "dataset_test_csv = pd.read_csv(dataset_test_csv_path)\n",
    "dataset_test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd75a82-9439-4045-87d8-28e3ebdb7ebd",
   "metadata": {},
   "source": [
    "#### Prepare dictionary for training image data and its Cobb angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31623532-1dc4-45ab-974b-6eca7867fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_dict = {} # good approach to maintain image - target_angle relation\n",
    "\n",
    "# get train image list and its path\n",
    "training_image_path = 'C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\data\\\\training\\\\'\n",
    "\n",
    "# get list of keys ie filepath\n",
    "training_image_filepath_key = dataset_training_csv['image_training_file'].values.tolist()\n",
    "\n",
    "# get list of values for dict\n",
    "training_cobb_angle_values = dataset_training_csv[['PT', 'MT', 'TL/L']].values\n",
    "\n",
    "# add to dictionary\n",
    "for i in range(len(training_image_filepath_key)):\n",
    "    training_dataset_dict[training_image_path + training_image_filepath_key[i]] = torch.tensor(training_cobb_angle_values[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f708d425-44ef-4485-89e7-3e411c433a46",
   "metadata": {},
   "source": [
    "#### Prepare dictionary for test image data and its Cobb angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b92c395-a63a-4a14-b958-5d5804361569",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_dict = {}\n",
    "test_image_path = 'C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\data\\\\test\\\\'\n",
    "test_image_filepath_key = dataset_test_csv['image_test_file'].values.tolist()\n",
    "test_cobb_angle_values = dataset_test_csv[['PT', 'MT', 'TL/L']].values\n",
    "\n",
    "for i in range(len(test_image_filepath_key)):\n",
    "    test_dataset_dict[test_image_path + test_image_filepath_key[i]] = torch.tensor(test_cobb_angle_values[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd0a48-5433-4d9f-91c4-570d4d3269a4",
   "metadata": {},
   "source": [
    "#### Prepare dictionary for training landmarks_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7978ad4-8354-425c-ba4c-efc1033efde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_landmark_ap_training = \"C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\training_dataset\\\\\"\n",
    "landmark_ap_training = pd.read_csv(path_landmark_ap_training + \"landmarks_ap.csv\", header=None)\n",
    "training_landmark_ap_key = landmark_ap_training.iloc[:,0].values.tolist()\n",
    "training_landmark_ap_values = landmark_ap_training.iloc[:,2:].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2ee3c2-71dd-4ff2-b897-577056d5d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_landmark_ap_dict = {} # key->image filepath, value->62 landmarks value\n",
    "\n",
    "for i in range(len(training_landmark_ap_key)):\n",
    "    training_landmark_ap_dict[training_image_path + training_landmark_ap_key[i]] = torch.tensor(training_landmark_ap_values[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1622ed1-0a45-4017-82ab-26a1f2ca1022",
   "metadata": {},
   "source": [
    "#### Prepare dictionary for test landmarks_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "773681f8-e8f7-4bd1-9d25-103e965603df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_landmark_ap_test = \"C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\test_dataset\\\\\"\n",
    "landmark_ap_test = pd.read_csv(path_landmark_ap_test + \"landmarks_ap.csv\", header=None)\n",
    "test_landmark_ap_key = landmark_ap_test.iloc[:,0].values.tolist()\n",
    "test_landmark_ap_values = landmark_ap_test.iloc[:,2:].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e8e3db-93e8-492d-a0e8-49a03a9fbc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_landmark_ap_dict = {} # key->image filepath, value->62 landmarks value\n",
    "\n",
    "for i in range(len(test_landmark_ap_key)):\n",
    "    test_landmark_ap_dict[test_image_path + test_landmark_ap_key[i]] = torch.tensor(test_landmark_ap_values[i], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a5ff7-b3f6-43be-aca9-37fd183e96a0",
   "metadata": {},
   "source": [
    "#### CustomDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7418c790-5c5f-410e-8eb2-e9546f22db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a2dee52-39cd-456c-9fb0-409443aec5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary dataset where key is image path and value is PT, MT, TL/L values\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_list, landmark_list, cobb_angle_list, transform_image_tensor, custom_img_resize_w_h=(255,255)):\n",
    "        self.images = image_list\n",
    "        self.landmarks = landmark_list\n",
    "        self.cobb_angles = cobb_angle_list\n",
    "        self.transform_image_tensor = transform_image_tensor\n",
    "        self.custom_img_resize_w_h = custom_img_resize_w_h\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index] # image_path is the key\n",
    "        \n",
    "        image = Image.open(image_path).convert('L')\n",
    "        \n",
    "        # custom resize image while maintaining aspect ratio\n",
    "        image = self.resize_with_padding(image, self.custom_img_resize_w_h)\n",
    "        \n",
    "        \n",
    "        # transform image if required\n",
    "        if self.transform_image_tensor is not None:\n",
    "            image = self.transform_image_tensor(image)\n",
    "        \n",
    "\n",
    "        # because U-net is hardcoded for 3 channel, duplicate another 2 channel\n",
    "        # image = torch.cat((image[:,:,:], image[:,:,:], image[:,:,:]), dim=0)\n",
    "        \n",
    "        return image, self.landmarks[index], self.cobb_angles[index], image_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def resize_with_padding(self, image, output_size):\n",
    "        original_width, original_height = image.size\n",
    "        target_width, target_height = output_size\n",
    "\n",
    "        # Calculate aspect ratios\n",
    "        aspect_ratio = original_width / original_height\n",
    "        target_ratio = target_width / target_height\n",
    "\n",
    "        # Calculate the new dimensions while maintaining aspect ratio\n",
    "        if aspect_ratio > target_ratio:\n",
    "            new_width = target_width\n",
    "            new_height = int(new_width / aspect_ratio)\n",
    "        else:\n",
    "            new_height = target_height\n",
    "            new_width = int(new_height * aspect_ratio)\n",
    "\n",
    "        # Resize the image while preserving the aspect ratio\n",
    "        resized_image = image.resize((new_width, new_height), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "        # Create a new image with the target size and paste the resized image onto it\n",
    "        padded_image = Image.new('L', (target_width, target_height))\n",
    "        x_offset = (target_width - new_width) // 2\n",
    "        y_offset = (target_height - new_height) // 2\n",
    "        padded_image.paste(resized_image, (x_offset, y_offset))\n",
    "\n",
    "        return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91900175-aa4c-4d76-9b85-22f182a09913",
   "metadata": {},
   "source": [
    "#### Tensor Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3305074f-6437-461d-8a66-a8d52c76a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1e4991-cc91-4b35-b108-fbac10313b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_images_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x - torch.min(x)) / (torch.max(x) - torch.min(x))),\n",
    "    transforms.Lambda(lambda x: x.type(torch.float32))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac196e0-3ff1-4102-89a8-2700fe328410",
   "metadata": {},
   "source": [
    "#### Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b957f2cf-1ec2-4933-b1dc-e5abf2dc8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6384c529-5f2f-4c5d-84ae-f086c36a6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to list before inputting into splitting function\n",
    "training_image_list = list(training_dataset_dict.keys())\n",
    "training_landmark_list = list(training_landmark_ap_dict.values())\n",
    "training_true_cobb_angle_list = list(training_dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aae46f5-49a2-4a17-9503-502d565ae77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the lists into training and validation sets\n",
    "training_image, val_image, training_landmark, val_landmark, training_true_cobb_angle, val_true_cobb_angle = train_test_split(training_image_list, training_landmark_list, training_true_cobb_angle_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bc12ad-fa3a-46b8-b6bd-6619f3eff18e",
   "metadata": {},
   "source": [
    "#### Custom Dataset instance for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1821b09-8541-44a9-8093-91eb33d3446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_training_dataset = CustomDataset(training_image, training_landmark, training_true_cobb_angle, transform_images_tensor, (572,572))\n",
    "transformed_validation_dataset = CustomDataset(val_image, val_landmark, val_true_cobb_angle, transform_images_tensor, (572,572))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8706771e-06ae-4b54-ada2-aedfe3de33d4",
   "metadata": {},
   "source": [
    "#### training_loader and validation_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90a36ad7-2a30-47d8-b8cc-e29e49b8cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Create a data loader for batching and shuffling the data\n",
    "# batch_size = 32\n",
    "\n",
    "training_loader = DataLoader(transformed_training_dataset, batch_size=5, shuffle=True)\n",
    "validation_loader =  DataLoader(transformed_validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696f3f26-a9c1-492c-b08b-f1bca3a1f4c9",
   "metadata": {},
   "source": [
    "#### Training and validating process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c468c094-4972-4203-9657-e675dbee673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47119490-8434-4c68-8b9f-db3fe729504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiInputNet(landmark_input_size=64, landmark_output_size=64)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7eb9fc3d-0946-4761-8751-003e2a8d4843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up optimizer and loss function\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b137f6f1-cf7b-486a-9392-5acac220fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 94.86462999319102, Validation Loss: 67.7224314728963\n",
      "Lowest val_loss found\n",
      "Epoch [2/100], Training Loss: 74.6244807429128, Validation Loss: 65.22831030481869\n",
      "Lowest val_loss found\n",
      "Epoch [3/100], Training Loss: 39.59007618644021, Validation Loss: 26.04401188228548\n",
      "Lowest val_loss found\n",
      "Epoch [4/100], Training Loss: 14.842717941705283, Validation Loss: 12.828108992158752\n",
      "Lowest val_loss found\n",
      "Epoch [5/100], Training Loss: 11.876406322826039, Validation Loss: 12.429247685314454\n",
      "Lowest val_loss found\n",
      "Epoch [6/100], Training Loss: 12.177212588198774, Validation Loss: 12.153602333412957\n",
      "Lowest val_loss found\n",
      "Epoch [7/100], Training Loss: 11.76763207571847, Validation Loss: 12.196447946976141\n",
      "Epoch [8/100], Training Loss: 11.531400522628388, Validation Loss: 12.212855662881713\n",
      "Epoch [9/100], Training Loss: 11.025111288219303, Validation Loss: 11.901237187926302\n",
      "Lowest val_loss found\n",
      "Epoch [10/100], Training Loss: 11.701283519918269, Validation Loss: 12.391848097296105\n",
      "Epoch [11/100], Training Loss: 11.234387193407331, Validation Loss: 11.708243478204786\n",
      "Lowest val_loss found\n",
      "Epoch [12/100], Training Loss: 11.547892319691645, Validation Loss: 12.056898658960751\n",
      "Epoch [13/100], Training Loss: 11.105611386237207, Validation Loss: 13.52169530231928\n",
      "Epoch [14/100], Training Loss: 11.154854923099666, Validation Loss: 12.197499154615649\n",
      "Epoch [15/100], Training Loss: 11.24001261785433, Validation Loss: 11.674226953196772\n",
      "Lowest val_loss found\n",
      "Epoch [16/100], Training Loss: 11.210966289817513, Validation Loss: 11.697119138904453\n",
      "Epoch [17/100], Training Loss: 10.840420023187415, Validation Loss: 11.861456906672606\n",
      "Epoch [18/100], Training Loss: 10.975593353246714, Validation Loss: 15.026860269381828\n",
      "Epoch [19/100], Training Loss: 10.85004675852788, Validation Loss: 11.387890122907677\n",
      "Lowest val_loss found\n",
      "Epoch [20/100], Training Loss: 10.936232845504563, Validation Loss: 14.080116271204556\n",
      "Epoch [21/100], Training Loss: 10.735107372333477, Validation Loss: 12.132989352204136\n",
      "Epoch [22/100], Training Loss: 10.72803345593539, Validation Loss: 11.39228206742363\n",
      "Epoch [23/100], Training Loss: 10.486330716640918, Validation Loss: 11.803856828394009\n",
      "Epoch [24/100], Training Loss: 10.809823797894763, Validation Loss: 11.349918563341356\n",
      "Lowest val_loss found\n",
      "Epoch [25/100], Training Loss: 10.679148831924834, Validation Loss: 11.517372631381468\n",
      "Epoch [26/100], Training Loss: 10.306379222250603, Validation Loss: 11.329509185147039\n",
      "Lowest val_loss found\n",
      "Epoch [27/100], Training Loss: 11.021138962213096, Validation Loss: 13.243660469337836\n",
      "Epoch [28/100], Training Loss: 11.060596701386688, Validation Loss: 11.594036546103734\n",
      "Epoch [29/100], Training Loss: 10.317428407730993, Validation Loss: 11.818378079797803\n",
      "Epoch [30/100], Training Loss: 1772.7207794189453, Validation Loss: 13.138401261617227\n",
      "Epoch [31/100], Training Loss: 854.5135929212942, Validation Loss: 52.21569490432739\n",
      "Epoch [32/100], Training Loss: 22.69524147758236, Validation Loss: 14.48508403703724\n",
      "Epoch [33/100], Training Loss: 20902852.07400088, Validation Loss: 16.251193273006027\n",
      "Epoch [34/100], Training Loss: 11999542.511165839, Validation Loss: 13.984086453146542\n",
      "Epoch [35/100], Training Loss: 14.918476754968816, Validation Loss: 11.733414466540838\n",
      "Epoch [36/100], Training Loss: 14.239971526257403, Validation Loss: 11.497906872599396\n",
      "Epoch [37/100], Training Loss: 14.323195098282454, Validation Loss: 12.33210167165884\n",
      "Epoch [38/100], Training Loss: 14.1414894562263, Validation Loss: 11.821471241331592\n",
      "Epoch [39/100], Training Loss: 13.28205709023909, Validation Loss: 12.35406118662087\n",
      "Epoch [40/100], Training Loss: 14.248369216918945, Validation Loss: 11.943311008595929\n",
      "Epoch [41/100], Training Loss: 14.023736260154031, Validation Loss: 11.796430919588227\n",
      "Epoch [42/100], Training Loss: 13.660712632265957, Validation Loss: 12.230561626633419\n",
      "Epoch [43/100], Training Loss: 13.715185310933498, Validation Loss: 12.049830144828128\n",
      "Epoch [44/100], Training Loss: 55525670.06252175, Validation Loss: 30.173710953329028\n",
      "Epoch [45/100], Training Loss: 24.6169747934713, Validation Loss: 19.040124947262793\n",
      "Epoch [46/100], Training Loss: 19.837036405290878, Validation Loss: 15.786634934931687\n",
      "Epoch [47/100], Training Loss: 23897074.187371936, Validation Loss: 40.78540510246434\n",
      "Epoch [48/100], Training Loss: 50.68049794977362, Validation Loss: 35.7484826334973\n",
      "Epoch [49/100], Training Loss: 33.75672326769148, Validation Loss: 21.139894073771448\n",
      "Epoch [50/100], Training Loss: 29.116780553545272, Validation Loss: 17.629753518196726\n",
      "Epoch [51/100], Training Loss: 25.579243666165834, Validation Loss: 16.81790379503953\n",
      "Epoch [52/100], Training Loss: 23.311756567521527, Validation Loss: 17.295462076350585\n",
      "Epoch [53/100], Training Loss: 21.425746310840953, Validation Loss: 14.78448633281226\n",
      "Epoch [54/100], Training Loss: 20.295784064701625, Validation Loss: 14.361528454214028\n",
      "Epoch [55/100], Training Loss: 18.880139911329593, Validation Loss: 12.769264820233449\n",
      "Epoch [56/100], Training Loss: 17.76172717825159, Validation Loss: 13.946111036791015\n",
      "Epoch [57/100], Training Loss: 18.038694802816813, Validation Loss: 13.23208333121747\n",
      "Epoch [58/100], Training Loss: 18.35281686039714, Validation Loss: 13.630652710142517\n",
      "Epoch [59/100], Training Loss: 18.082974749726134, Validation Loss: 12.598004121871032\n",
      "Epoch [60/100], Training Loss: 15.9206680849001, Validation Loss: 13.447367802185497\n",
      "Epoch [61/100], Training Loss: 17.400964997031473, Validation Loss: 12.996828161333639\n",
      "Epoch [62/100], Training Loss: 15.741895873825271, Validation Loss: 12.12180029854332\n",
      "Epoch [63/100], Training Loss: 15.876186822916006, Validation Loss: 11.882620259044097\n",
      "Epoch [64/100], Training Loss: 15.48641260258563, Validation Loss: 12.153133931233711\n",
      "Epoch [65/100], Training Loss: 16.24589761511072, Validation Loss: 11.771244662016937\n",
      "Epoch [66/100], Training Loss: 15.539160969969513, Validation Loss: 12.055513244928774\n",
      "Epoch [67/100], Training Loss: 17.051744250508097, Validation Loss: 13.01552046482096\n",
      "Epoch [68/100], Training Loss: 16.404639027335428, Validation Loss: 12.258753201703435\n",
      "Epoch [69/100], Training Loss: 16.7751557083873, Validation Loss: 12.226371376784806\n",
      "Epoch [70/100], Training Loss: 16.184374964082394, Validation Loss: 12.419662528124052\n",
      "Epoch [71/100], Training Loss: 15.76047624241222, Validation Loss: 11.922952558269206\n",
      "Epoch [72/100], Training Loss: 15.811298964859603, Validation Loss: 11.7733717886443\n",
      "Epoch [73/100], Training Loss: 1383694244.5017858, Validation Loss: 13.478131055447859\n",
      "Epoch [74/100], Training Loss: 8730138289.536215, Validation Loss: 16.64164107607812\n",
      "Epoch [75/100], Training Loss: 44998.91300686923, Validation Loss: 13.866579832489958\n",
      "Epoch [76/100], Training Loss: 20.70036366078761, Validation Loss: 14.704886073304205\n",
      "Epoch [77/100], Training Loss: 18.362843810737907, Validation Loss: 14.442667460933174\n",
      "Epoch [78/100], Training Loss: 20.130994425191506, Validation Loss: 14.351183565007043\n",
      "Epoch [79/100], Training Loss: 19.495756564202246, Validation Loss: 13.370583739477334\n",
      "Epoch [80/100], Training Loss: 19.48408738668863, Validation Loss: 13.436372587975768\n",
      "Epoch [81/100], Training Loss: 18.78238922589785, Validation Loss: 14.415962965678922\n",
      "Epoch [82/100], Training Loss: 19.311185198944884, Validation Loss: 13.055417290053416\n",
      "Epoch [83/100], Training Loss: 19.12199678668728, Validation Loss: 14.450544624214935\n",
      "Epoch [84/100], Training Loss: 18.67761868006223, Validation Loss: 13.852380419822083\n",
      "Epoch [85/100], Training Loss: 18.25062164083704, Validation Loss: 13.781259368529025\n",
      "Epoch [86/100], Training Loss: 18.33349332871375, Validation Loss: 12.760305565657076\n",
      "Epoch [87/100], Training Loss: 18.819299858885927, Validation Loss: 12.807380461201225\n",
      "Epoch [88/100], Training Loss: 17.754298457851657, Validation Loss: 12.26316647369837\n",
      "Epoch [89/100], Training Loss: 17.698892413795768, Validation Loss: 12.910159713214206\n",
      "Epoch [90/100], Training Loss: 18.43787229215944, Validation Loss: 13.741441836062165\n",
      "Epoch [91/100], Training Loss: 19.14047881225487, Validation Loss: 13.311598518306447\n",
      "Epoch [92/100], Training Loss: 17.730388034473766, Validation Loss: 12.593371141817151\n",
      "Epoch [93/100], Training Loss: 509577.74338707986, Validation Loss: 13.801056153073754\n",
      "Epoch [94/100], Training Loss: 17.823051663188192, Validation Loss: 12.77036592272139\n",
      "Epoch [95/100], Training Loss: 18.109925455861276, Validation Loss: 12.479030579943018\n",
      "Epoch [96/100], Training Loss: 18.07181433268956, Validation Loss: 12.763854365066155\n",
      "Epoch [97/100], Training Loss: 16.209860566374545, Validation Loss: 12.980596967579164\n",
      "Epoch [98/100], Training Loss: 233926.7654011652, Validation Loss: 28.278232435398188\n",
      "Epoch [99/100], Training Loss: 23.790149837345272, Validation Loss: 14.836644502030206\n",
      "Epoch [100/100], Training Loss: 19.258473935065332, Validation Loss: 12.284651324613806\n"
     ]
    }
   ],
   "source": [
    "# to save validation loss and training loss\n",
    "loss_list_data = []\n",
    "\n",
    "# to keep track lowest loss\n",
    "lowest_val_loss = float('inf')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# training loop with validation\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # training phase\n",
    "    model.train()                                       # allow weights and biases adjusting\n",
    "    training_loss = 0.0\n",
    "    for image_input, landmark_input, target_angle, _ in training_loader:\n",
    "        # move input and output to cuda if available\n",
    "        image_input = image_input.to(device)\n",
    "        landmark_input = landmark_input.to(device)\n",
    "        # reshape target_angle\n",
    "        # target_angle = target_angle.reshape((3))\n",
    "        target_angle = target_angle.to(device)\n",
    "        optimizer.zero_grad()                           # clearing previous loss derivative\n",
    "        predicted = model(image_input, landmark_input)                  # forward \n",
    "        loss = criterion(predicted, target_angle)       # computing loss\n",
    "        loss.backward()                                 # computing loss derivative with respect of weights and biases\n",
    "        optimizer.step()                                # adjusting weights and biases\n",
    "        training_loss += loss.item()                    # summing all batches losses for averaging\n",
    "    training_loss /= len(training_loader)\n",
    "        \n",
    "    # validation phase in at end of every epoch\n",
    "    model.eval()                                        # block weights and biases adjsuting\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():                                # remove all computed derivatives\n",
    "        for image_input, landmark_input, target_angle, _ in validation_loader:\n",
    "            # move input and output to cuda if available\n",
    "            image_input = image_input.to(device)\n",
    "            landmark_input = landmark_input.to(device)\n",
    "            # reshape target_angle\n",
    "            # target_angle = target_angle.reshape((3))\n",
    "            target_angle = target_angle.to(device)\n",
    "            predicted = model(image_input, landmark_input)\n",
    "            # for averaging validation loss\n",
    "            val_loss += criterion(predicted, target_angle).item()\n",
    "    \n",
    "    val_loss /= len(validation_loader) # calculating average validation loss\n",
    "    \n",
    "    # Print the training and validation loss for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {training_loss}, Validation Loss: {val_loss}\")    \n",
    "    \n",
    "    # for graphing evaluation later\n",
    "    loss_list_data.append((epoch+1, training_loss, val_loss))\n",
    "    \n",
    "    # save best model with lowest validation loss\n",
    "    if lowest_val_loss > val_loss:\n",
    "        lowest_val_loss = val_loss\n",
    "        best_model = model.state_dict()\n",
    "        print('Lowest val_loss found')\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# save the best model found\n",
    "path = 'C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\saved_models\\\\training_5\\\\'\n",
    "torch.save(best_model, path + 'best_training_5.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15452a8-c017-403c-8f7c-8b697136a705",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eab86c3f-7baf-4897-896b-cdf2f46f4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (image_input, landmark_input, target_angle, _) in enumerate(training_loader):\n",
    "#     print(\"Batch \" + str(idx+1))\n",
    "#     print(\"landmark shape \" + str(landmark_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaf9dfd9-1f41-4c9c-8736-300f6721bcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_mock = torch.rand((5,1,572,572))\n",
    "# landmark_mock = torch.rand((5,64))\n",
    "\n",
    "# img_mock = img_mock.to(device)\n",
    "# landmark_mock = landmark_mock.to(device)\n",
    "# model(img_mock, landmark_mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9335a2c-2300-42ac-87e7-7e7bf4a26a65",
   "metadata": {},
   "source": [
    "#### Compute training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3141aa3-c04c-4fbe-bce6-fefe408aa0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time elapsed: 9816.097136259079 seconds\n"
     ]
    }
   ],
   "source": [
    "training_time = end_time - start_time\n",
    "print(\"Training time elapsed: \" + str(training_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e059a5-5856-40c3-ae1d-6eb87c618352",
   "metadata": {},
   "source": [
    "#### Save latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cefb1565-44b4-4d87-9ed5-9a046e8e0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model \n",
    "path = 'C:\\\\Users\\\\iqmal_pc\\\\Desktop\\\\fyp_experiment\\\\saved_models\\\\training_5\\\\'\n",
    "torch.save(model.state_dict(), path + 'finished_training_5.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61981682-72b2-40bb-acb3-c05d39951579",
   "metadata": {},
   "source": [
    "#### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d6e614a-fed1-463a-87d3-4b2a623c9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack list\n",
    "test_image = list(test_dataset_dict.keys())\n",
    "test_true_cobb_angle = list(test_dataset_dict.values())\n",
    "test_landmark = list(test_landmark_ap_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90ee1f64-a234-4a82-93e7-b0276915477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "transformed_test_dataset = CustomDataset(test_image, test_landmark, test_true_cobb_angle, transform_images_tensor, (572,572))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db0fa676-cc49-498e-89e0-05c40ef42984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data loader\n",
    "test_loader =  DataLoader(transformed_test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afcd1f71-f37c-4cc6-adf2-9806202dbdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model testing loss: 9.920594838215038\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for image_input, landmark_input, target_angle, _ in test_loader:\n",
    "        # move input and output to cuda if available\n",
    "        image_input = image_input.to(device)\n",
    "        landmark_input = landmark_input.to(device)\n",
    "        # reshape target_angle\n",
    "        # target_angle = target_angle.reshape((3))\n",
    "        target_angle = target_angle.to(device)\n",
    "        predicted = model(image_input, landmark_input)\n",
    "        test_loss += criterion(predicted, target_angle).item()\n",
    "\n",
    "test_loss /= len(test_loader) # calculating average test_loss\n",
    "print(f\"Final model testing loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81fbd43c-2cc2-4d8d-b4ba-dc2400e11090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model testing loss: 53.88561197370291\n"
     ]
    }
   ],
   "source": [
    "# load best model\n",
    "the_best_model = MultiInputNet(landmark_input_size=64, landmark_output_size=64)\n",
    "the_best_model.load_state_dict(torch.load(path + 'best_training_5.pt'), strict=False) # load the saved best model weights & biases dictionary\n",
    "the_best_model = the_best_model.to(device)\n",
    "# testing phase using best model\n",
    "test_loss = 0.0\n",
    "the_best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for image_input, landmark_input, target_angle, _ in test_loader:\n",
    "        # move input and output to cuda if available\n",
    "        image_input = image_input.to(device)\n",
    "        landmark_input = landmark_input.to(device)\n",
    "        # reshape target_angle\n",
    "        # target_angle = target_angle.reshape((3))\n",
    "        target_angle = target_angle.to(device)\n",
    "        predicted = the_best_model(image_input, landmark_input)\n",
    "        test_loss += criterion(predicted, target_angle).item()\n",
    "\n",
    "test_loss /= len(test_loader) # calculating average test_loss\n",
    "print(f\"Best model testing loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d719981-c7c3-4343-951d-35d27c8e08c5",
   "metadata": {},
   "source": [
    "#### Evaluation (Loss vs Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6788895-2a45-4e44-ac5f-100833040119",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = []\n",
    "training_loss_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "for i in range(len(loss_list_data)):\n",
    "    epoch_list.append(loss_list_data[i][0])\n",
    "    training_loss_list.append(loss_list_data[i][1])\n",
    "    validation_loss_list.append(loss_list_data[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e4731be-1e40-463c-bfb7-e9c415cc0680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training loss vs epoch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_list, training_loss_list, color='#f70c0c', label='training loss')\n",
    "plt.plot(epoch_list, validation_loss_list, color='#00fa08', label='validation loss')\n",
    "plt.title('Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86ca27-e998-4662-99e3-501bf2b45e77",
   "metadata": {},
   "source": [
    "#### Test data evaluation plot (Predicted vs Ground Truth) for every PT, MT and TL/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ce6f6a3-2d01-4d4a-94e4-b92f2a5acccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "target_angle_list = []\n",
    "\n",
    "the_best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for image_input, landmark_input, target_angle, _ in test_loader:\n",
    "        # move input and output to cuda if available\n",
    "        image_input = image_input.to(device)\n",
    "        landmark_input = landmark_input.to(device)\n",
    "        # reshape target_angle\n",
    "        target_angle = target_angle.reshape((3))\n",
    "        target_angle = target_angle.to(device)\n",
    "        predicted = the_best_model(image_input, landmark_input)\n",
    "        \n",
    "        predicted_list.append(predicted.cpu().numpy())\n",
    "        target_angle_list.append(target_angle.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55fcd26c-ddb9-40ae-8ef4-2a42f30748ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined PT (predicted, true)\n",
    "PT_value = [(PT_predicted, PT_true) for (PT_predicted,*_),(PT_true,*_) in zip(predicted_list,target_angle_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "efc818b1-0cec-4745-9fe2-2f3f13041d80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m MT_value \u001b[38;5;241m=\u001b[39m [(MT_predicted,MT_true) \u001b[38;5;28;01mfor\u001b[39;00m (_,MT_predicted,_),(_,MT_true,_) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(predicted_list,target_angle_list)]\n",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m MT_value \u001b[38;5;241m=\u001b[39m [(MT_predicted,MT_true) \u001b[38;5;28;01mfor\u001b[39;00m (_,MT_predicted,_),(_,MT_true,_) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(predicted_list,target_angle_list)]\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "MT_value = [(MT_predicted,MT_true) for (_,MT_predicted,_),(_,MT_true,_) in zip(predicted_list,target_angle_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a7096b6-f5e7-4b74-9802-3a02030f54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_value = [(TL_predicted,TL_true) for (*_,TL_predicted),(*_,TL_true) in zip(predicted_list,target_angle_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cbc82668-a7be-4621-891a-11efe919a343",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m predicted_pt \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m PT_value]\n\u001b[0;32m      5\u001b[0m true_pt \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m PT_value]\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted PT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#fc0505\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x, true_pt, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue PT\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#05fc4f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Image ID\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\pyplot.py:2790\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2785\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[0;32m   2787\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2788\u001b[0m         vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2789\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, plotnonfinite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2790\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[0;32m   2791\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39ms, c\u001b[38;5;241m=\u001b[39mc, marker\u001b[38;5;241m=\u001b[39mmarker, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   2792\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin, vmax\u001b[38;5;241m=\u001b[39mvmax, alpha\u001b[38;5;241m=\u001b[39malpha, linewidths\u001b[38;5;241m=\u001b[39mlinewidths,\n\u001b[0;32m   2793\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39medgecolors, plotnonfinite\u001b[38;5;241m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2795\u001b[0m     sci(__ret)\n\u001b[0;32m   2796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1425\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1426\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1427\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4520\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4518\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m   4519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m-> 4520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4523\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   4524\u001b[0m          mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot PT value\n",
    "\n",
    "x = [img_idx for img_idx in range(1, len(PT_value)+1)]\n",
    "predicted_pt = [item[0] for item in PT_value]\n",
    "true_pt = [item[1] for item in PT_value]\n",
    "\n",
    "plt.scatter(x, predicted_pt, label='predicted PT', color='#fc0505', s=5)\n",
    "plt.plot(x, true_pt, label='true PT', color='#05fc4f')\n",
    "plt.xlabel('Test Image ID')\n",
    "plt.ylabel('PT angle')\n",
    "plt.title('PT angle vs Test Image ID')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd55bb-975a-43b7-8baf-6c71ef8a0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot MT value\n",
    "x = [img_idx for img_idx in range(1, len(MT_value)+1)]\n",
    "predicted_mt = [item[0] for item in MT_value]\n",
    "true_mt = [item[1] for item in MT_value]\n",
    "\n",
    "plt.scatter(x, predicted_mt, label='predicted MT', color='#fc0505', s=5)\n",
    "plt.plot(x, true_mt, label='true MT', color='#05fc4f')\n",
    "plt.xlabel('Test Image ID')\n",
    "plt.ylabel('MT angle')\n",
    "plt.title('MT angle vs Test Image ID')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2046941d-a031-4996-9b9e-cc5c953bc538",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m predicted_tl \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m TL_value]\n\u001b[0;32m      4\u001b[0m true_tl \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m TL_value]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_tl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted TL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#fc0505\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x, true_tl, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue TL\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#05fc4f\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Image ID\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\pyplot.py:2790\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2785\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[0;32m   2786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[0;32m   2787\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2788\u001b[0m         vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2789\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, plotnonfinite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2790\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[0;32m   2791\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39ms, c\u001b[38;5;241m=\u001b[39mc, marker\u001b[38;5;241m=\u001b[39mmarker, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   2792\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin, vmax\u001b[38;5;241m=\u001b[39mvmax, alpha\u001b[38;5;241m=\u001b[39malpha, linewidths\u001b[38;5;241m=\u001b[39mlinewidths,\n\u001b[0;32m   2793\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39medgecolors, plotnonfinite\u001b[38;5;241m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2794\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2795\u001b[0m     sci(__ret)\n\u001b[0;32m   2796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\__init__.py:1423\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1425\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1426\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1427\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4520\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4518\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[0;32m   4519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[1;32m-> 4520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4523\u001b[0m     s \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_internal.classic_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   4524\u001b[0m          mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines.markersize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot TL value\n",
    "x = [img_idx for img_idx in range(1, len(TL_value)+1)]\n",
    "predicted_tl = [item[0] for item in TL_value]\n",
    "true_tl = [item[1] for item in TL_value]\n",
    "\n",
    "plt.scatter(x, predicted_tl, label='predicted TL', color='#fc0505', s=5)\n",
    "plt.plot(x, true_tl, label='true TL', color='#05fc4f')\n",
    "plt.xlabel('Test Image ID')\n",
    "plt.ylabel('TL angle')\n",
    "plt.title('TL angle vs Test Image ID')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa753e1-b669-4a7f-9b86-59de8439b937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
